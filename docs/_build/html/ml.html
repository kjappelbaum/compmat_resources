

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Machine Learning &mdash; Computational Materials Science Resources  documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Math" href="math.html" />
    <link rel="prev" title="Coding" href="coding.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> Computational Materials Science Resources
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="coding.html">Coding</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Machine Learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#online-courses">Online Courses</a></li>
<li class="toctree-l2"><a class="reference internal" href="#articles">Articles</a></li>
<li class="toctree-l2"><a class="reference internal" href="#books">Books</a></li>
<li class="toctree-l2"><a class="reference internal" href="#python-packages">Python Packages</a></li>
<li class="toctree-l2"><a class="reference internal" href="#various-trivia">Various trivia</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="math.html">Math</a></li>
<li class="toctree-l1"><a class="reference internal" href="plotting.html">Plotting</a></li>
<li class="toctree-l1"><a class="reference internal" href="electronic_structure_codes.html">Electronic Structure Codes</a></li>
<li class="toctree-l1"><a class="reference internal" href="dft.html">QM and DFT theoretical background</a></li>
<li class="toctree-l1"><a class="reference internal" href="classical.html">Classical simulations</a></li>
<li class="toctree-l1"><a class="reference internal" href="fun.html">Fun</a></li>
<li class="toctree-l1"><a class="reference internal" href="open_science.html">Open Science</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Computational Materials Science Resources</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Machine Learning</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/ml.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="machine-learning">
<h1>Machine Learning<a class="headerlink" href="#machine-learning" title="Permalink to this headline">¶</a></h1>
<p>Machine Learning is getting a central part of our field. There is a <a class="reference external" href="https://github.com/josephmisiti/awesome-machine-learning">huge curated list with all kinds
of ML frameworks and packages</a></p>
<p>The most recent advances can be found with paper and code on <a class="reference external" href="https://paperswithcode.com/">paperswithcode</a></p>
<div class="section" id="online-courses">
<h2>Online Courses<a class="headerlink" href="#online-courses" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="articles">
<h2>Articles<a class="headerlink" href="#articles" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><a class="reference external" href="https://arxiv.org/abs/1811.12808">Model Evaluation, Model Selection, and Algorithm Selection in Machine Learning</a>
focusses on classification problems but still is a great resource of how to perform performance evaluations (regarding multiple testing remember the probability for type-1 error for multiple testing is
<span class="math">\(1-(1-\alpha)^n\)</span>, where <span class="math">\(n\)</span> is the number of test and <span class="math">\(\alpha\)</span> the type-1 error rate of the single test).</li>
<li><a class="reference external" href="https://arxiv.org/abs/1803.08823">A high-bias, low-variance introduction to Machine Learning for physicists</a> is a nice introduction to core ML techniques.</li>
</ul>
</div>
<div class="section" id="books">
<h2>Books<a class="headerlink" href="#books" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="python-packages">
<h2>Python Packages<a class="headerlink" href="#python-packages" title="Permalink to this headline">¶</a></h2>
<ul>
<li><p class="first"><a class="reference external" href="https://github.com/slundberg/shap">shap</a> : Shapely values are a nice way
to bring interpretability to Machine Learning. The
<a class="reference external" href="https://christophm.github.io/interpretable-ml-book/shapley.html">intepretable machine learning book</a>
gives an overview over this and other methods for interpretable ML</p>
</li>
<li><p class="first">holoviews</p>
</li>
<li><p class="first"><a class="reference external" href="https://github.com/pandas-profiling/pandas-profiling">pandas profiling</a> gives some more useful information
for exploratory data analysis than <code class="code docutils literal"><span class="pre">df.describe()</span></code></p>
</li>
<li><p class="first"><a class="reference external" href="https://github.com/WillKoehrsen/feature-selector">feature selector</a>
is a useful package for intial steps of feature engineering</p>
</li>
<li><p class="first">If you already have (ASE) trajectories around, then <a class="reference external" href="https://amp.readthedocs.io/en/latest/">AMP</a> can be nice
to build a ML model based on them</p>
</li>
<li><p class="first"><a class="reference external" href="http://www.qmlcode.org/">QML</a> has a similar goal. It has efficient implementations to calculate representations
and kernels</p>
</li>
<li><p class="first"><a class="reference external" href="https://github.com/hackingmaterials/matminer">matminer</a> is really useful to compute common descriptors</p>
</li>
<li><p class="first"><a class="reference external" href="http://edwardlib.org/">Edward</a> is a nice package for probabilistic modelling like bayesian neural nets.</p>
</li>
<li><p class="first"><a class="reference external" href="https://docs.pymc.io/">PyMC3</a> is a popular package for probabilistic programming</p>
</li>
<li><p class="first"><a class="reference external" href="https://github.com/ResidentMario/missingno">missingno</a> is a nice package for analzying missing data</p>
</li>
<li><p class="first"><a class="reference external" href="https://github.com/dswah/pyGAM">pyGAM</a> is a python implementation of <a class="reference external" href="https://web.stanford.edu/~hastie/Papers/gam.pdf">generalized additive models</a> (a nice overview of GAMs is in a <a class="reference external" href="https://multithreaded.stitchfix.com/blog/2015/07/30/gam/">blogpost from Kim Larsen</a>)</p>
</li>
<li><p class="first"><a class="reference external" href="https://eli5.readthedocs.io/en/latest/overview.html">eli5</a> is a nice package visualize the explanations of mostely white-box models.</p>
</li>
<li><p class="first"><a class="reference external" href="https://github.com/bckenstler/CLR">i like to cycle my learning rates</a> . Related is the great idea of <a class="reference external" href="https://openreview.net/pdf?id=BJYwwY9ll">snapshot ensembles</a>  I hope to find time at some point to generalize the <a class="reference external" href="https://github.com/titu1994/Snapshot-Ensembles">keras implemtation</a> a bit more. This blogpost gives a great overview <a class="reference external" href="https://www.jeremyjordan.me/nn-learning-rate/">https://www.jeremyjordan.me/nn-learning-rate/</a></p>
</li>
<li><p class="first">something that I starting using way to late is tensorboard, in keras it is simply this callback</p>
<div class="highlight-default"><div class="highlight"><pre><span></span> <span class="n">tbCallBack</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">TensorBoard</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s1">&#39;logs&#39;</span><span class="p">,</span>
                                      <span class="n">histogram_freq</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">write_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                      <span class="n">write_images</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">followed</span> <span class="n">by</span>

<span class="p">::</span>

      <span class="n">tensorboard</span> <span class="o">--</span><span class="n">logdir</span> <span class="n">logs</span>

<span class="n">to</span> <span class="n">actually</span> <span class="n">start</span> <span class="n">tensorboard</span><span class="o">.</span>
</pre></div>
</div>
</li>
<li><p class="first">Magpie is not only a <a class="reference external" href="https://en.wikipedia.org/wiki/Magpie">brid</a> but also <a class="reference external" href="https://www.nature.com/articles/npjcompumats201628">a ML framework for inorganic materials</a></p>
</li>
<li><p class="first"><a class="reference external" href="https://github.com/yzhao062/pyod">PyOD</a> contains loads of different tools for outlier detection</p>
</li>
<li><p class="first"><a class="reference external" href="https://github.com/EpistasisLab/tpot">tpot is a powerful way to optimize complete ML pipelines</a></p>
</li>
<li><p class="first"><a class="reference external" href="https://github.com/tensorflow/adanet">Everyone knows it: Adanet by google</a></p>
</li>
</ul>
</div>
<div class="section" id="various-trivia">
<h2>Various trivia<a class="headerlink" href="#various-trivia" title="Permalink to this headline">¶</a></h2>
<ul>
<li><p class="first">An underappreciated measure of centreal tendency is the trimean (<span class="math">\(TM\)</span>)</p>
<blockquote>
<div><div class="math">
\[TM = \frac{Q_1 + 2Q_1 + Q_3}{4},\]</div>
</div></blockquote>
<p>where <span class="math">\(QM_2\)</span> is the median and <span class="math">\(Q_1\)</span> and <span class="math">\(Q_2\)</span> are the quartiles.</p>
<blockquote>
<div><p>“An advantage of the trimean as a measure of the center (of a distribution) is that it combines the median’s emphasis on center values with the midhinge’s attention to the extremes.” — Herbert F. Weisberg, Central Tendency and Variability.</p>
</div></blockquote>
</li>
<li><p class="first">It is quite useful to keep the following <a class="reference external" href="https://commons.wikimedia.org/wiki/File:P-value_nomograph_for_Bayesian_posterior_estimation.jpg">nomogram</a> in mind</p>
<blockquote>
<div><a class="reference internal image-reference" href="_images/P-value_nomograph_for_Bayesian_posterior_estimation.jpg"><img alt="P value nomogram" class="align-center" src="_images/P-value_nomograph_for_Bayesian_posterior_estimation.jpg" style="width: 500px;" /></a>
</div></blockquote>
<dl class="docutils">
<dt>This is directly connected to</dt>
<dd><p class="first last">“Extraordinary claims require extraordinary evidence” – Carl Sagan/Laplace</p>
</dd>
</dl>
</li>
<li><p class="first">A nice visualization of the famous <a class="reference external" href="https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124">Ioannidis paper</a> is this <a class="reference external" href="http://shiny.ieis.tue.nl/PPV/">RShiny app</a></p>
</li>
<li><p class="first">A quite interesting discussion of the variance in the output function is reduced by adding more parameters to a (ensembled) network which then leads to a lower generalization error. They also provide a discussion of a divergence of the error at <span class="math">\(N^*\)</span> for networks without regularization. Preprint version is on <a class="reference external" href="https://export.arxiv.org/pdf/1901.01608">arXiv:1901.01608v3</a></p>
<blockquote>
<div><a class="reference internal image-reference" href="_images/generalization_error_parameters.jpg"><img alt="Measured generalization error as a function of the number of parameters (arXiv:1901.01608v3)" class="align-center" src="_images/generalization_error_parameters.jpg" style="width: 500px;" /></a>
</div></blockquote>
</li>
<li><p class="first">I find <a class="reference external" href="https://arxiv.org/pdf/1511.07122.pdf">dilated convolutional NNs</a> to be quite a interesting way to increase the perceptive field. Ferenc Huszár gives another description in terms of <a class="reference external" href="https://www.inference.vc/dilated-convolutions-and-kronecker-factorisation/">Kronecker factorizations of smaller kernels</a></p>
</li>
<li><p class="first"><a class="reference external" href="https://arxiv.org/pdf/1411.4280.pdf">Spatial dropout</a> is quite interesting to make dropout work better on spatial correlations.</p>
</li>
<li><p class="first"><a class="reference external" href="https://chemrxiv.org/articles/Graph-based_Genetic_Algorithm_and_Generative_Model_Monte_Carlo_Tree_Search_for_the_Exploration_of_Chemical_Space/7240751">Jensen’s paper about GA for logP optimization</a> and also a recent work from <a class="reference external" href="https://www.nature.com/articles/s41467-019-08483-9">Berend Smit’s group</a> are reminders that we shouldn’t forget good old techniques such as GA.</p>
</li>
</ul>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="math.html" class="btn btn-neutral float-right" title="Math" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="coding.html" class="btn btn-neutral" title="Coding" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Kevin M. Jablonka

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    
    
      <script type="text/javascript">
          var DOCUMENTATION_OPTIONS = {
              URL_ROOT:'./',
              VERSION:'',
              LANGUAGE:'None',
              COLLAPSE_INDEX:false,
              FILE_SUFFIX:'.html',
              HAS_SOURCE:  true,
              SOURCELINK_SUFFIX: '.txt'
          };
      </script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    

  

  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>